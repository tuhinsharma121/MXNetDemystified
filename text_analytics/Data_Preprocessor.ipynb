{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataframe = pd.read_csv(\"./data/text/training_data_50000.csv\")\n",
    "test_dataframe = pd.read_csv(\"./data/text/test_data_50000.csv\")\n",
    "epochs = 10\n",
    "vec_size = 64\n",
    "num_cores = 4\n",
    "pred_to_context_word_dist_thresh = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc_label = list(training_dataframe[\"Index\"])\n",
    "train_sentiment_label = np.array(training_dataframe[\"Sentiment\"])\n",
    "train_sentiment_text = list(training_dataframe[\"SentimentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield LabeledSentence(words=doc.split(),tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = LabeledLineSentence(train_sentiment_text, train_doc_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done for epoch :  0\n",
      "Training done for epoch :  1\n",
      "Training done for epoch :  2\n",
      "Training done for epoch :  3\n",
      "Training done for epoch :  4\n",
      "Training done for epoch :  5\n",
      "Training done for epoch :  6\n",
      "Training done for epoch :  7\n",
      "Training done for epoch :  8\n",
      "Training done for epoch :  9\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(size=vec_size,window=pred_to_context_word_dist_thresh,workers=num_cores,alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "model.build_vocab(sentences)\n",
    "for epoch in range(10):\n",
    "    print(\"Training done for epoch : \",epoch)\n",
    "    model.train(sentences=sentences)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no deca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.empty((len(train_sentiment_text),vec_size))\n",
    "train_label = train_sentiment_label\n",
    "for i in range(len(train_sentiment_text)):\n",
    "    train_data[i] = model.docvecs[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_dict = dict()\n",
    "train_data_dict[\"data\"] = train_data.tolist()\n",
    "train_data_dict[\"label\"] = train_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/train_data_50000.json', 'w') as fp:\n",
    "    json.dump(train_data_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentiment_label = np.array(test_dataframe[\"Sentiment\"])\n",
    "test_sentiment_text = list(test_dataframe[\"SentimentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = np.empty((len(test_sentiment_text),vec_size))\n",
    "test_label = test_sentiment_label\n",
    "for i in range(len(test_sentiment_text)):\n",
    "    test_data[i] = model.infer_vector(doc_words=test_sentiment_text[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_dict = dict()\n",
    "test_data_dict[\"data\"] = test_data.tolist()\n",
    "test_data_dict[\"label\"] = test_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('./data/test_data_50000.json', 'w') as fp:\n",
    "    json.dump(test_data_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
